{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment classification with LSTM\n",
    "In this notebook we will use LSTMs to do sentiment classification on the [imdb dataset](http://ai.stanford.edu/~amaas/data/sentiment/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from spacy.symbols import ORTH\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the data: <br>\n",
    "`wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_dataset():\n",
    "    ! mkdir -p data/aclImdb\n",
    "    ! wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "    ! tar -zxvf aclImdb_v1.tar.gz -C data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpack_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/aclImdb/imdbEr.txt'),\n",
       " PosixPath('data/aclImdb/imdb.vocab'),\n",
       " PosixPath('data/aclImdb/models'),\n",
       " PosixPath('data/aclImdb/train'),\n",
       " PosixPath('data/aclImdb/test'),\n",
       " PosixPath('data/aclImdb/README')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "PATH = Path(\"data/aclImdb/\")\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = PATH/\"train/pos/0_9.txt\"\n",
    "path.read_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first time run this\n",
    "#!python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "def sub_br(x): return re_br.sub(\"\\n\", x)\n",
    "\n",
    "my_tok = spacy.load('en')\n",
    "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bromwell', 'High', 'is', 'a', 'cartoon', 'comedy', '.', 'It', 'ran', 'at']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = PATH/\"train/pos/0_9.txt\"\n",
    "spacy_tok(path.read_text())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/aclImdb/train/pos/10544_8.txt'),\n",
       " PosixPath('data/aclImdb/train/pos/9530_9.txt'),\n",
       " PosixPath('data/aclImdb/train/pos/9901_8.txt'),\n",
       " PosixPath('data/aclImdb/train/pos/11951_8.txt'),\n",
       " PosixPath('data/aclImdb/train/pos/7441_7.txt')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_files = list((PATH/\"train\"/\"pos\").iterdir())\n",
    "neg_files = list((PATH/\"train\"/\"neg\").iterdir())\n",
    "all_files = pos_files + neg_files\n",
    "all_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes some time\n",
    "counts = Counter()\n",
    "for path in all_files:\n",
    "    counts.update(spacy_tok(path.read_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103504"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in list(counts):\n",
    "    if counts[word] < 5:\n",
    "        del counts[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33907"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = {\"<PAD>\":0, \"UNK\":1}\n",
    "words = [\"<PAD>\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy_tok takes a while. Run it just once\n",
    "def encode_sentence(path, vocab2index, N=400, padding_start=True):\n",
    "    x = spacy_tok(path.read_text())\n",
    "    enc = np.zeros(N, dtype=np.int32)\n",
    "    enc1 = np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in x])\n",
    "    l = min(N, len(enc1))\n",
    "    if padding_start:\n",
    "        enc[:l] = enc1[:l]\n",
    "    else:\n",
    "        enc[N-l:] = enc1[:l]\n",
    "    return enc, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            1,  1782,     4,  2723,     4,    29,    36,    37,    15,\n",
       "         2388,   320,     6,    23,   351,     8,   316,   254,   680,\n",
       "         1382,   103,   334,  7723,   103, 12826,     3,   369,   951,\n",
       "            3, 16949,    19,  1791,    55,  1573,    36,     1,   153,\n",
       "           16,  9449,  1070,   349,    79,    31,  3864,   118,   179,\n",
       "         3504,    23,    13,    44,  6231,    23,  5043,   214,  3491,\n",
       "          301,   254,  1967,    16,  1749,  3525,   174,    12,    78,\n",
       "         1774,  6181,    19,  1070,    70,    36,  2723,  1070,  2007,\n",
       "        23762,    31,   731,   128,  1031,    55,   372,   174,   316,\n",
       "         2459,    19,  1840,    31,    23,   654,   271,  1635,    19,\n",
       "         6647,    31,   186,    14,    22,    23,  6502,  1184,    13,\n",
       "        14378,    31,   195,   243, 16949,   194, 13988, 14402,    19,\n",
       "          174,    78,   262,   976,    70,    50,    31, 27226,   500,\n",
       "          249,   195,    10,     1,   325, 12860,    22,    78,    68,\n",
       "           84,    55,  7244,    91,    31,  2057,  1205,     4,    50,\n",
       "            4,   316,  1966,   134,    16,  2492,    10, 14700,    44,\n",
       "          350,   117,  3776,    36,  1629,   751,  1291,   153,    96,\n",
       "         3659,  4531,    31,   502,  5259,    31,    40,   127,   128,\n",
       "         1031,    55,   372,    36,    37,    15,  6072, 28530,  5475,\n",
       "           19,   358,    31,    76,    23,  1201,  1727,    47,    22,\n",
       "         1170,    16,  1749,    13,    69,    67,    23,  1555,    68,\n",
       "         1507,  7723, 12826,    31,   186,  1849,    46,  1070,   153,\n",
       "          199,  1070, 10712,    19,   350,    46,  1140,   214,    32,\n",
       "          128, 22121,    95,   214,   276,   143,    55,    16,   992,\n",
       "           22,    23,    13,  3247,   103, 32518,   458,    16,   844,\n",
       "         7470,  1749,   729,    31,     6,   343,   184,    16,  1749,\n",
       "           19,   142,     1,    36,  1289,  2447,    12,  1070,  1669,\n",
       "            8,   171,    72,    36,   908,  7219,   729,  1070,    16,\n",
       "        13988,   751,  1354,     3,    36,  1135,   566,  8803,   745,\n",
       "           19,    16,  7712,  9449,  1549,    31,   794,   142,  1967,\n",
       "         7723, 12826,    71,    10,  1171,    12,    31,    99,    43,\n",
       "          142,   128,   200,   115,    69,  2723,  2832,    59,  1070,\n",
       "          974,    43,    31,  2057, 23614,   196,   174,   564,    36,\n",
       "        18581,  1388,   249,   171,    10,    96,   939,   215,    15,\n",
       "        13483,    59,   174,    31], dtype=int32),\n",
       " 310)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = PATH/\"train/neg/211_4.txt\"\n",
    "encode_sentence(path, vocab2index, N=400, padding_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImdbDataset(Dataset):\n",
    "    def __init__(self, PATH, train=\"train\", N=400, padding_start=True):\n",
    "        self.path_to_images = PATH/train\n",
    "        self.pos_files = list((self.path_to_images/\"pos\").iterdir())\n",
    "        self.neg_files = list((self.path_to_images/\"neg\").iterdir())\n",
    "        self.files = self.pos_files + self.neg_files\n",
    "        # pos 1, neg 0\n",
    "        self.y = np.concatenate((np.ones(len(self.pos_files), dtype=int),\n",
    "                                np.zeros(len(self.neg_files), dtype=int)), axis=0)\n",
    "        # it is important to run encode_sentence in the init\n",
    "        self.X = [encode_sentence(path, vocab2index, N, padding_start) for path in self.files]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, s = self.X[idx]\n",
    "        return x, s, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_v0 = ImdbDataset(PATH, padding_start=False)\n",
    "valid_ds_v0 = ImdbDataset(PATH, \"test\", padding_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "train_dl_v0 = DataLoader(train_ds_v0, batch_size=batch_size, shuffle=True)\n",
    "valid_dl_v0 = DataLoader(valid_ds_v0, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 181, 182, 183, 184,  91,  36, 185,  31, 186,\n",
       "         50, 187, 188, 189,  84, 190, 191,  91, 174,  12, 192, 193, 194,\n",
       "         31, 195, 196, 197, 198,  70, 174,  78,  14,  15,  16, 199, 103,\n",
       "        200, 201, 202, 142, 203,  25, 204,  31,  76, 163, 164,   3,  16,\n",
       "        205, 206,  68, 207,  27, 142, 208, 209, 210,  19, 211, 212,  95,\n",
       "         16, 213, 214, 186, 215,  15, 216,  59,  71,  78,  34, 217,   3,\n",
       "        218, 219, 220, 218, 160, 221, 220, 218, 222,  31,  76, 223,  15,\n",
       "         16,  54,  59,  71,   3, 224,   3,  72,   4,  69, 225,   4,  70,\n",
       "        210,  78,  36, 226, 227, 103, 228, 115, 229, 230, 212,  31, 210,\n",
       "         85, 231, 232, 233,  78, 220, 234,  84, 235, 236,  55, 237, 238,\n",
       "         36, 239,  57, 240,   3, 241, 242, 243, 244, 240, 245,  55, 118,\n",
       "         16, 246, 228,  59, 247, 214, 248, 249,  76, 250,  69,  70,  16,\n",
       "        205,  78,  19,  70,  18,  70,  16,  66,  78,   3,  16, 251, 252,\n",
       "         15, 174, 187,  78, 253, 182,   3, 254, 255, 256, 257, 258, 256,\n",
       "         91,  84, 259,  31,  61, 260,  78,  34, 261,  31], dtype=int32),\n",
       " 188,\n",
       " 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_v0[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding LSTMs \n",
    "\n",
    "nn.LSTM() <br>\n",
    "`input_size` – The dimension of the embedding for each word <br>\n",
    "`hidden_size` – The number of features in the hidden state h <br>\n",
    "`num_layers` – Number of recurrent layers <br>\n",
    "`batch_first` – If True, then the input and output tensors are provided as (batch, seq, feature) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3183,  0.3120],\n",
       "         [-0.8239,  2.5844],\n",
       "         [-0.4005,  1.1637],\n",
       "         [ 0.7870,  0.8620],\n",
       "         [-0.9666,  1.1664],\n",
       "         [ 1.5673, -0.7956],\n",
       "         [ 1.1117,  1.0850]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [torch.randn(1, 2) for _ in range(7)] # make a sequence of length 7\n",
    "inputs = torch.cat(inputs).view(1, len(inputs), -1)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size x sequence length x embedding size\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=2, hidden_size=4, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, (hidden, cell) = lstm(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM V0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMV0Model(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super(LSTMV0Model,self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        _, (ht, _) = self.lstm(x)\n",
    "        return self.linear(ht[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs_v0(model, optimizer, train_dl, val_dl, epochs=10):\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, s, y in train_dl:\n",
    "            # s is not used in this model\n",
    "            x = x.long().cuda()\n",
    "            y = y.float().cuda()\n",
    "            y_pred = model(x)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc = val_metrics_v0(model, val_dl)\n",
    "        if i % 5 == 1:\n",
    "            print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics_v0(model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x, s, y in valid_dl:\n",
    "        # s is not used here\n",
    "        x = x.long().cuda()\n",
    "        y = y.float().unsqueeze(1).cuda()\n",
    "        y_hat = model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        y_pred = y_hat > 0\n",
    "        correct += (y_pred.float() == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "train_dl = DataLoader(train_ds_v0, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds_v0, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33909\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "model = LSTMV0Model(vocab_size, 50, 50).cuda()\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.683 val loss 0.677 and val accuracy 0.572\n",
      "train loss 0.622 val loss 0.668 and val accuracy 0.642\n",
      "train loss 0.487 val loss 0.560 and val accuracy 0.741\n",
      "train loss 0.380 val loss 0.528 and val accuracy 0.797\n",
      "train loss 0.285 val loss 0.700 and val accuracy 0.788\n",
      "train loss 0.245 val loss 0.593 and val accuracy 0.823\n"
     ]
    }
   ],
   "source": [
    "train_epocs_v0(model, optimizer, train_dl, valid_dl, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.192 val loss 0.635 and val accuracy 0.828\n",
      "train loss 0.181 val loss 0.626 and val accuracy 0.829\n",
      "train loss 0.175 val loss 0.677 and val accuracy 0.821\n",
      "train loss 0.170 val loss 0.686 and val accuracy 0.823\n",
      "train loss 0.164 val loss 0.662 and val accuracy 0.828\n",
      "train loss 0.159 val loss 0.702 and val accuracy 0.825\n"
     ]
    }
   ],
   "source": [
    "update_optimizer(optimizer, lr=0.001)\n",
    "train_epocs_v0(model, optimizer, train_dl, valid_dl, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Model \n",
    "GRU have less parameters but often have as good or better performance than an LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUV0Model(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super(GRUV0Model,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        _, ht = self.gru(x)\n",
    "        return self.linear(ht[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(words)\n",
    "model = GRUV0Model(vocab_size, 50, 50).cuda()\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.685 val loss 0.678 and val accuracy 0.564\n",
      "train loss 0.599 val loss 0.659 and val accuracy 0.677\n",
      "train loss 0.458 val loss 0.976 and val accuracy 0.604\n",
      "train loss 0.302 val loss 0.647 and val accuracy 0.763\n",
      "train loss 0.199 val loss 0.624 and val accuracy 0.812\n",
      "train loss 0.139 val loss 0.581 and val accuracy 0.839\n"
     ]
    }
   ],
   "source": [
    "train_epocs_v0(model, optimizer, train_dl, valid_dl, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.106 val loss 0.572 and val accuracy 0.849\n",
      "train loss 0.104 val loss 0.586 and val accuracy 0.847\n",
      "train loss 0.097 val loss 0.605 and val accuracy 0.846\n",
      "train loss 0.096 val loss 0.603 and val accuracy 0.847\n",
      "train loss 0.093 val loss 0.610 and val accuracy 0.849\n",
      "train loss 0.090 val loss 0.631 and val accuracy 0.846\n"
     ]
    }
   ],
   "source": [
    "update_optimizer(optimizer, lr=0.001)\n",
    "train_epocs_v0(model, optimizer, train_dl, valid_dl, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with variable length\n",
    "dynamic padding + pack_padded_sequence\n",
    "\n",
    "`pack_padded_sequence` packs a Tensor containing padded sequences of variable length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence_no_padding(path, vocab2index):\n",
    "    x = spacy_tok(path.read_text())\n",
    "    return np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = PATH/\"train/neg/211_4.txt\"\n",
    "#encode_sentence_no_padding(path, vocab2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImdbDataset2(Dataset):\n",
    "    def __init__(self, PATH, train=\"train\"):\n",
    "        self.path_to_images = PATH/train\n",
    "        self.pos_files = list((self.path_to_images/\"pos\").iterdir())\n",
    "        self.neg_files = list((self.path_to_images/\"neg\").iterdir())\n",
    "        self.files = self.pos_files + self.neg_files\n",
    "        # pos 1, neg 0\n",
    "        self.y = np.concatenate((np.ones(len(self.pos_files), dtype=int),\n",
    "                                np.zeros(len(self.neg_files), dtype=int)), axis=0)\n",
    "        # it is important to run encode_sentence in the init\n",
    "        self.X = [encode_sentence_no_padding(path, vocab2index) for path in self.files]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        return x, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ImdbDataset2(PATH)\n",
    "valid_ds = ImdbDataset2(PATH, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2,   3,   4,   5,   4,   6,   7,   8,   3,   9,  10,  11,  12,\n",
       "          3,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,\n",
       "         25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  14,  35,   3,\n",
       "         36,  37,  15,  38,  19,  36,  39,  31,  40,   3,  41,  42,  43,\n",
       "         44,  45,  46,  47,  16,  48,  49,   3,  50,  51,  19,  36,  52,\n",
       "         53,  22,  54,  33,  55,  56,  57,  58,  59,  36,  60,  31,  61,\n",
       "         62,  12,   3,   4,  63,   4,   6,  64,   8,   3,  13,  47,  29,\n",
       "         65,  66,   3,  67,  43,  13,  68,  44,  69,  70,   4,   5,   4,\n",
       "         67,  71,  72,  16,  54,  73,  74,  57,  58,  75,  31,  76,   4,\n",
       "         77,   4,  78,  79,  80,  18,  19,  81,   9,  82,  83,  55,  84,\n",
       "         85,   5,  86,  85,   3,  87,  16,  54,  88,  75,  59,  36,  80,\n",
       "         89,  90,  91,  92,  93,  88,  94,  95,  91,  16,  54,  57,  95,\n",
       "         91,  58,  59,  96,  97,  98,  31,  99, 100,  15,  36, 101, 102,\n",
       "        103, 104,   6, 105, 106,  15,  16, 107, 108,  19, 109, 110, 111,\n",
       "         57,  22,   8,   3,   4,  77,   4,  78,  36, 112,  19, 113, 114,\n",
       "         22, 115, 116, 117, 118, 119,  36, 120, 121,  29, 122, 123,  19,\n",
       "        124,  29,  16, 125, 126, 127, 128, 129,  31, 130,  75,   1, 131,\n",
       "        132,  91,  36,  50, 133, 134,  36,  44, 135, 136,  15, 137,  31,\n",
       "        138,  38,  19,  36, 139, 140, 141,   3,  22,  10,  47, 142, 143,\n",
       "         17, 144,  15,  93,  19, 142, 145,  68, 146,  94, 147,  22,  31,\n",
       "        148,   4,   5,   4,  78,  36, 149,  97,  19,   4,  63,   4, 150,\n",
       "          3,   4,  77,   4,  78, 151,  16, 152,  67, 153,  16, 154,  93,\n",
       "        124, 155,  31,  76, 156,  12, 157,  88,  75,  22,  36, 158, 133,\n",
       "        159, 160,  94, 147,  34,  36, 161, 162,  31, 163, 164,  22,  16,\n",
       "         12, 165, 166,   3,  67,  65, 167, 133, 159,  36, 168,  19,   1,\n",
       "        169, 170,  31, 171,  10, 172,  94,  55, 118, 173,  29, 174,  12,\n",
       "        175, 176,  78,  36, 177, 178,  19,  36, 179,  89,  97,  22,  23,\n",
       "         33,  59,  30, 180,   4,   5,   4,  31]),\n",
       " 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collate_fn function\n",
    "The `collate_fn` merges a list of samples to form a mini-batch. It is an optional parameter to our data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"Creates mini-batch tensors from the list of tuples (sentences, labels).\n",
    "    \n",
    "    Need custom collate_fn because merging sequences (including padding) is not \n",
    "    supported in default. Sequences are padded to the maximum length of mini-batch \n",
    "    sequences (dynamic padding).\n",
    "    \n",
    "    Args:\n",
    "        data: list of tuple (sentence, label). \n",
    "            - list of word indices of variable length\n",
    "            - label, 0 or 1\n",
    "    Returns:\n",
    "        packed_batch: (PackedSequence), see torch.nn.utils.rnn.pack_padded_sequence\n",
    "        sencences: torch tensor of shape (batch_size, max_len).\n",
    "        labels: torch tensor of shape (batch_size, 1).\n",
    "        lengths: list; valid length for each padded sentence. \n",
    "    \"\"\"\n",
    "    # Sort a data list by sentences length (descending order).\n",
    "    #data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    sentences, labels = zip(*data)\n",
    "    \n",
    "    # stack labels\n",
    "    labels = torch.Tensor(labels)\n",
    "    \n",
    "    # Merge sentences\n",
    "    lengths = [len(s) for s in sentences]\n",
    "   \n",
    "    sents = torch.zeros(len(sentences), max(lengths)).long()\n",
    "    for i, s in enumerate(sentences):\n",
    "        end = lengths[i]\n",
    "        sents[i, :end] = torch.Tensor(s[:end])        \n",
    "    \n",
    "    return sents, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny example of our data\n",
    "data = [([4, 545, 23, 1], 0), ([34, 84], 1), ([23, 6, 774], 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  4, 545,  23,   1],\n",
       "         [ 34,  84,   0,   0],\n",
       "         [ 23,   6, 774,   0]]),\n",
       " [4, 2, 3],\n",
       " tensor([0., 1., 0.]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note how the data ir reorder and padded\n",
    "collate_fn(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more realistic example\n",
    "data = [train_ds[0], train_ds[1], train_ds[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  2,   3,   4,  ...,   0,   0,   0],\n",
       "         [181, 182, 183,  ...,   0,   0,   0],\n",
       "         [156,  12, 262,  ..., 271, 281, 214]]),\n",
       " [359, 188, 710],\n",
       " tensor([1., 1., 1.]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collate_fn(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents, lengths, labels = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1089]), torch.Size([5]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[134, 1089, 431, 292, 323]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super(GRUModel,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        pack = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        _, ht = self.gru(pack)\n",
    "        return self.linear(ht[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, optimizer, train_dl, valid_dl, epochs=10):\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, s, y in train_dl:\n",
    "            x = x.long().cuda()\n",
    "            y = y.float().cuda()\n",
    "            y_pred = model(x, s)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        if i % 5 == 1:\n",
    "            print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x, s, y in valid_dl:\n",
    "        x = x.long().cuda()\n",
    "        y = y.float().unsqueeze(1).cuda()\n",
    "        y_hat = model(x, s)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        y_pred = y_hat > 0\n",
    "        correct += (y_pred.float() == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(words)\n",
    "model = GRUModel(vocab_size, 50, 50).cuda()\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.671 val loss 0.621 and val accuracy 0.652\n",
      "train loss 0.491 val loss 0.723 and val accuracy 0.740\n",
      "train loss 0.266 val loss 0.485 and val accuracy 0.837\n",
      "train loss 0.160 val loss 0.405 and val accuracy 0.875\n",
      "train loss 0.110 val loss 0.457 and val accuracy 0.880\n",
      "train loss 0.087 val loss 0.599 and val accuracy 0.858\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, optimizer, train_dl, valid_dl, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.056 val loss 0.587 and val accuracy 0.872\n",
      "train loss 0.055 val loss 0.576 and val accuracy 0.873\n",
      "train loss 0.052 val loss 0.590 and val accuracy 0.873\n",
      "train loss 0.049 val loss 0.590 and val accuracy 0.874\n",
      "train loss 0.050 val loss 0.597 and val accuracy 0.875\n",
      "train loss 0.047 val loss 0.610 and val accuracy 0.873\n"
     ]
    }
   ],
   "source": [
    "update_optimizer(optimizer, lr=0.001)\n",
    "train_epocs(model, optimizer, train_dl, valid_dl, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reordering in the forward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back to padding\n",
    "train_ds = ImdbDataset(PATH, padding_start=True)\n",
    "valid_ds= ImdbDataset(PATH, \"test\", padding_start=True)\n",
    "\n",
    "batch_size = 7\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "x, s, y = next(iter(train_dl)) # here s is the length of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 400]), torch.Size([7]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([230, 213, 400, 188, 169, 274, 323])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by length so we can use pack_padded_sequence\n",
    "s, index = s.sort(0, descending=True)\n",
    "x = x[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([400, 323, 274, 230, 213, 188, 169])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 6, 5, 0, 1, 3, 4])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(words)\n",
    "embedding_dim = 10\n",
    "embed = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 400, 10])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = embed(x.long())\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 9\n",
    "lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN will not perform calculation on pad elements if pack_padded_sequence is used\n",
    "x_pack = pack_padded_sequence(x, list(s), batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pack, (ht, ct) = lstm(x_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 9])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## final hidden layer\n",
    "ht.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 9])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0780],\n",
       "        [-0.0163],\n",
       "        [-0.0245],\n",
       "        [-0.0111],\n",
       "        [-0.0230],\n",
       "        [-0.0821],\n",
       "        [-0.0500]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(hidden_dim, 1)\n",
    "y_hat = linear(ht[-1])\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes back to the original ordering\n",
    "h = torch.zeros_like(y_hat).scatter_(0, index.unsqueeze(1), y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0111],\n",
       "        [-0.0230],\n",
       "        [-0.0780],\n",
       "        [-0.0821],\n",
       "        [-0.0500],\n",
       "        [-0.0245],\n",
       "        [-0.0163]], grad_fn=<ScatterBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0780],\n",
       "        [-0.0163],\n",
       "        [-0.0245],\n",
       "        [-0.0111],\n",
       "        [-0.0230],\n",
       "        [-0.0821],\n",
       "        [-0.0500]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 6, 5, 0, 1, 3, 4])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with sorting in the forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super(LSTMModel,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x, s):\n",
    "        # sorting\n",
    "        s, sort_index = torch.sort(s, 0,descending=True)\n",
    "        s = s.numpy().tolist()\n",
    "        x = x[sort_index]\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        x_pack = pack_padded_sequence(x, s, batch_first=True)\n",
    "        out_pack, (ht, ct) = self.lstm(x_pack)\n",
    "        out = self.linear(ht[-1])\n",
    "        return torch.zeros_like(out).scatter_(0, sort_index.unsqueeze(1).cuda(), out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33909\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "model = LSTMModel(vocab_size, 50, 50).cuda()\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.665 val loss 0.634 and val accuracy 0.639\n",
      "train loss 0.450 val loss 0.752 and val accuracy 0.710\n",
      "train loss 0.425 val loss 0.639 and val accuracy 0.767\n",
      "train loss 0.223 val loss 0.562 and val accuracy 0.829\n",
      "train loss 0.172 val loss 0.478 and val accuracy 0.861\n",
      "train loss 0.125 val loss 0.617 and val accuracy 0.850\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, optimizer, train_dl, valid_dl, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.100 val loss 0.665 and val accuracy 0.851\n",
      "train loss 0.092 val loss 0.679 and val accuracy 0.851\n",
      "train loss 0.089 val loss 0.705 and val accuracy 0.848\n",
      "train loss 0.083 val loss 0.704 and val accuracy 0.851\n",
      "train loss 0.082 val loss 0.697 and val accuracy 0.852\n",
      "train loss 0.081 val loss 0.739 and val accuracy 0.847\n"
     ]
    }
   ],
   "source": [
    "update_optimizer(optimizer, 0.001)\n",
    "train_epocs(model, optimizer, train_dl, valid_dl, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir $PATH/\"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PATH/\"models/model-855.pth\"\n",
    "save_model(model, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7423409295082092, tensor(0.8471, device='cuda:0'))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU model with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x, s):\n",
    "        s, sort_index = torch.sort(s, 0,descending=True)\n",
    "        s = s.numpy().tolist()\n",
    "        x = x[sort_index]\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        x_pack = pack_padded_sequence(x, list(s), batch_first=True)\n",
    "        out_pack, ht= self.gru(x_pack)\n",
    "        out = self.linear(ht[-1])\n",
    "        return torch.zeros_like(out).scatter_(0, sort_index.unsqueeze(1).cuda(), out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional and multiple layers GRUs / LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 7\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "x,s,y = next(iter(train_dl)) # here s is the length of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(words)\n",
    "embedding_dim = 10\n",
    "hidden_dim = 9\n",
    "embed = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "lstm1 = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "lstm2 = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, index = s.sort(0, descending=True)\n",
    "x = x[index]\n",
    "x = embed(x.long())\n",
    "x_pack = pack_padded_sequence(x, list(s), batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_out, (ht, ct) = lstm1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 9])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 9])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht[-2,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_out, (ht2, ct2) = lstm2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7, 9])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 9]), torch.Size([7, 9]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht2[-2,:,:].shape, ht2[-1,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 18])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concat the final forward (ht[-2,:,:]) and backward (ht[-1,:,:]) hidden layers      \n",
    "h = torch.cat((ht2[-2,:,:], ht2[-1,:,:]), dim = 1)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGRUModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super(BiGRUModel,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, batch_first=True,\n",
    "                          dropout=0.3, bidirectional=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.linear = nn.Linear(2*hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x, s):\n",
    "        s, sort_index = torch.sort(s, 0,descending=True)\n",
    "        s = s.numpy().tolist()\n",
    "        x = x[sort_index]\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        x_pack = pack_padded_sequence(x, s, batch_first=True)\n",
    "        out_pack, ht = self.gru(x_pack)\n",
    "        h = torch.cat((ht[-2,:,:], ht[-1,:,:]), dim = 1)\n",
    "        h = self.linear(h)\n",
    "        return torch.zeros_like(h).scatter_(0, sort_index.unsqueeze(1).cuda(), h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(words)\n",
    "model = BiGRUModel(vocab_size, 50, 50).cuda()\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.661 val loss 0.662 and val accuracy 0.569\n",
      "train loss 0.297 val loss 0.366 and val accuracy 0.863\n",
      "train loss 0.150 val loss 0.392 and val accuracy 0.879\n",
      "train loss 0.090 val loss 0.421 and val accuracy 0.883\n",
      "train loss 0.056 val loss 0.526 and val accuracy 0.879\n",
      "train loss 0.038 val loss 0.584 and val accuracy 0.872\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, optimizer, train_dl, valid_dl, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.028 val loss 0.644 and val accuracy 0.875\n",
      "train loss 0.023 val loss 0.673 and val accuracy 0.873\n",
      "train loss 0.022 val loss 0.675 and val accuracy 0.873\n",
      "train loss 0.019 val loss 0.700 and val accuracy 0.872\n",
      "train loss 0.020 val loss 0.718 and val accuracy 0.870\n",
      "train loss 0.019 val loss 0.730 and val accuracy 0.871\n"
     ]
    }
   ],
   "source": [
    "update_optimizer(optimizer, 0.001)\n",
    "train_epocs(model, optimizer, train_dl, valid_dl, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model in this notebook is adapted from this [pytorch tutorial](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
